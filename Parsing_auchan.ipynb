{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not translate host name \"HOST\" to address: Unknown host\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m DBPASS  \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBPASS\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m PORT    \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPORT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 25\u001b[0m greenplum \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDBUSER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDBPASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m gp_cursor \u001b[38;5;241m=\u001b[39m greenplum\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: could not translate host name \"HOST\" to address: Unknown host\n"
     ]
    }
   ],
   "source": [
    "# pip install requests BeautifulSoup4 lxml\n",
    "# pip install pygame\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import math\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "#import os,  glob\n",
    "#import csv\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Офрмление\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# Для подключение к БД                                  \n",
    "HOST    ='HOST'\n",
    "DB      ='DB'\n",
    "DBUSER  ='DBUSER'\n",
    "DBPASS  ='DBPASS'\n",
    "PORT    ='PORT'\n",
    "\n",
    "greenplum = psycopg2.connect(host = HOST, database = DB, user = DBUSER, password = DBPASS)\n",
    "gp_cursor = greenplum.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оформление\n",
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "   background-color: transparent !important;\n",
    "}\n",
    ".jp-OutputArea-output {\n",
    "   background-color: transparent;\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем класс "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response:\n",
    "    def __init__(self):\n",
    "        self.url = 'https://www.auchan.ru'\n",
    "        self.start_time = time.time()\n",
    "        self.style= {'bar_color':'#f08080'}\n",
    "        self.layout = Layout(width='20%', height='20px')\n",
    "\n",
    "    def start_respond(self, type):\n",
    "        if type == 'test':\n",
    "            response = requests.get(self.url, verify=False)\n",
    "            response.raise_for_status()\n",
    "            print(response)\n",
    "        \n",
    "        elif type == 'main':\n",
    "            main_links = []\n",
    "            folder_name = []\n",
    "            response = requests.get(self.url, verify=False)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            \n",
    "            for link in soup.find_all('___', '________________'):\n",
    "                main_links.append(self.url+link.get('href'))\n",
    "                folder_name.append(link.get('href').replace('/catalog/', \"\").replace('/', \"\").replace('-', \"_\"))\n",
    "    \n",
    "            return main_links\n",
    "        \n",
    "    def respond(self, links, type, page_type):\n",
    "        progress = IntProgress(min = 0, max = len(links), style=self.style, layout=self.layout)\n",
    "        display(progress)\n",
    "        num = 0\n",
    "        resp_links = []\n",
    "\n",
    "        for s_link in links:\n",
    "            try:\n",
    "                response = requests.get(s_link, verify=False)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "                if type == 'category':\n",
    "\n",
    "                    for link in soup.find_all('___', '________________'):\n",
    "                        resp_links.append(self.url+link.get('href'))\n",
    "        \n",
    "                elif type == 'uncategory':\n",
    "\n",
    "                    for link in soup.find_all('___', '________________'):\n",
    "                        resp_links.append(self.url+link.get('href'))\n",
    "\n",
    "                elif type == 'pages':\n",
    "\n",
    "                    if page_type == 'category':\n",
    "                        n = soup.find('___', '________________').text            # Для количества товаров в категории\n",
    "                    elif page_type == 'uncategory':\n",
    "                        n = soup.find('___', '________________').text            # Для количества товаров в подкатегории\n",
    "                        \n",
    "                    page = 1\n",
    "                    n = n.replace('(',\"\").replace(')', \"\")\n",
    "                    max_page = math.ceil(int(n)/40)\n",
    "\n",
    "                    while page <= max_page:\n",
    "                        resp_links.append(s_link+'?page={}'.format(page))\n",
    "                        page += 1\n",
    "\n",
    "                elif type == 'products':\n",
    "\n",
    "                    for link in soup.find_all('___', '________________'):\n",
    "                        resp_links.append(s_link+link.get('href'))\n",
    "\n",
    "                num += 1    \n",
    "                perc = round((num / len(links)) * 100, 2)\n",
    "                end_time = time.time()\n",
    "                predict = round((((end_time - self.start_time)/num)*(len(links)-num))/60,2)\n",
    "                print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN  ||   '.format(num, len(links), perc, predict), end='\\r')\n",
    "                \n",
    "                output = wi.Output()\n",
    "                progress.value = num\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print ('SOMETHING IS WRONG WITH {}      '.format(s_link), end='\\r')\n",
    "                pass\n",
    "            \n",
    "        return resp_links\n",
    "\n",
    "def redactor(links, type, want_to_split):           # TESTING\n",
    "    \n",
    "    prod = pd.DataFrame(links)\n",
    "    prod.to_csv (\"full_path.csv\", index=False)\n",
    "\n",
    "    if type == 'category':\n",
    "        names=['1','2','3','4','category','uncategory','5','product','name','6']\n",
    "    elif type == 'uncategory':\n",
    "        names=['1','2','3','4','category','uncategory','subcategory','5','product','name','6']\n",
    "    \n",
    "    path_prod=pd.read_csv('full_path.csv', names=names, encoding='cp1251', sep='/', skiprows=1)\n",
    "    path_prod = path_prod.drop(columns=['1','2','3','4','5','6'])\n",
    "    path_prod['path'] = 'https://www.auchan.ru/product/' + path_prod['name'] +'/'\n",
    "\n",
    "    if want_to_split == True:\n",
    "        \n",
    "    return path_prod\n",
    "\n",
    "R = response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = R.start_respond(type = 'main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_links = R.respond(type = 'category', links = links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем полную информацию о ссылках на продукты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_full_path = pd.DataFrame(full_path_art)\n",
    "df_full_path.to_csv (\"full_path.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prod=pd.read_csv('full_path.csv',names=['1','2','3','4','category','subcategory','5','product','name','6'],\n",
    "encoding='cp1251',sep='/', skiprows=1)\n",
    "path_prod = path_prod.drop(columns=['1','2','3','4','5','6'])\n",
    "path_prod['path'] = 'https://www.auchan.ru/product/' + path_prod['name'] +'/'\n",
    "path_prod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразуем данные для разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prod=pd.read_csv('full_path.csv',names=['1','2','3','4','category','subcategory','5','product','name','6'],\n",
    "encoding='cp1251',sep='/', skiprows=1)\n",
    "path_prod = path_prod.drop(columns=['1','2','3','4','5','6'])\n",
    "path_prod['path'] = 'https://www.auchan.ru/product/' + path_prod['name'] +'/'\n",
    "\n",
    "cat = path_prod.category.unique()\n",
    "files_name = []\n",
    "\n",
    "for cat_name in cat:\n",
    "    df = path_prod.loc[(path_prod['category'] == cat_name)]\n",
    "    df = df.drop(columns=['category','subcategory','product','name'])\n",
    "    file_name = \"{}_part\".format(cat_name)\n",
    "    df.to_csv ('{}.csv'.format(file_name), index= False, header= False, sep=';')\n",
    "    files_name.append(file_name)\n",
    "\n",
    "prodycts_links = []\n",
    "for i in files_name:\n",
    "    prodycts_links.append(i+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор категории для загрузки товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(prodycts_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = 'aziya_part.csv'        # выбрать категорию из списка выше\n",
    "prod_cat=pd.read_csv(file, names=['links'])\n",
    "prod_cat = prod_cat['links'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем имя товара и артикул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "name_art = []\n",
    "links = 0\n",
    "leng = len(prod_cat)\n",
    "progress = IntProgress(min = 0, max = leng, value = links, style={'bar_color': '#f08080'}, layout=Layout(width='20%', height='20px'))\n",
    "display(progress)      \n",
    "\n",
    "for file in prod_cat:\n",
    "    try:\n",
    "        response = requests.get(file, verify=False)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        name_art.append(file + soup.find('__','___________').text + '/'+ soup.find('td','css-1v23ygr').text)\n",
    "\n",
    "        links = links + 1\n",
    "        perc = round((links / leng) * 100, 2)\n",
    "        end_time = time.time()\n",
    "        predict = round((((end_time - start_time)/links)*(leng-links))/60,2)\n",
    "        print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN    '.format(links,leng,perc,predict), end='\\r')\n",
    "\n",
    "    except Exception as e:\n",
    "        print (' SOMETHING IS WRONG WITH {}           '.format(url), end='\\r')\n",
    "        pass\n",
    "\n",
    "    output = wi.Output()\n",
    "    progress.value = links\n",
    "\n",
    "#print(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(name_art)\n",
    "df.to_csv (\"df_final.csv\", index=False)       # УКАЗАТЬ ИМЯ ДЛЯ ИТОГОВОГО ФАЙЛА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('df_final.csv')\n",
    "df = df['0'].str.split('/', expand=True)\n",
    "df.columns=['0','1','2','3','Имя_ENG','Наименование','Артикул','7']\n",
    "df = df.drop(columns=['0','1','2','3','7'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение полученных данных с данными из Dbeaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod = \"\"\"\n",
    "select sku, lvl_1, lvl_2, lvl_3, lvl_4 from products\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products  =  pd.read_sql(query_prod, greenplum)\n",
    "products['sku'] = products['sku'].astype(str)\n",
    "products.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(products, df, left_on='sku', right_on='Артикул')\n",
    "df_merged = df_merged[['Артикул', 'Наименование', 'lvl_1', 'lvl_2', 'lvl_3','lvl_4']]\n",
    "df_merged = df_merged.drop_duplicates ()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись артикулов и продуктов и загрузка в SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art = pd.DataFrame(name_art)\n",
    "df_art.to_csv (\"prd_art.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для загрузки в базу\n",
    "conn = create_engine('________________________________________________')\n",
    "\n",
    "table_path = 'table_table'          #УКАЗАТЬ НАИМЕНОВАНИЕ ТАБЛИЦЫ В SAS\n",
    "df_merged.to_sql(name=table_path, con=conn, schema='public', if_exists='replace')\n",
    "print('Залито в базу, путь: {}'.format(table_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
