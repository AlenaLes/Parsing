{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install requests BeautifulSoup4 lxml\n",
    "# pip install pygame\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os,  glob\n",
    "import csv\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# Для подключение к БД\n",
    "import psycopg2                                    \n",
    "host = '__.__.___.___'\n",
    "database = '______'\n",
    "dbuser = '________'\n",
    "dbpassword = '_______'\n",
    "port='_______'\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "greenplum = psycopg2.connect(host = host, database = database, user = dbuser, password = dbpassword)\n",
    "gp_cursor = greenplum.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оформление\n",
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "   background-color: transparent !important;\n",
    "}\n",
    ".jp-OutputArea-output {\n",
    "   background-color: transparent;\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подкдлючаемся к основной странице\n",
    "url = 'https://www.auchan.ru/catalog'\n",
    "response = requests.get(url, verify=False)\n",
    "response.raise_for_status()\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Смотрим на основные категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.auchan.ru'\n",
    "main_links, folder_name = [], []\n",
    "\n",
    "for link in soup.find_all('__','_________________________________'):\n",
    "    main_links.append(url+link.get('href'))\n",
    "    folder_name.append(link.get('href').replace('/catalog/',\"\").replace('/',\"\").replace('-',\"_\"))\n",
    "\n",
    "print(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Достаем группы товаров из категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "category_links = []\n",
    "leng = len(main_links)\n",
    "links = 0\n",
    "progress = IntProgress(min = 0, max = len(main_links), value = links, style={'bar_color': '#f08080'}, layout=Layout(width='20%', height='20px'))\n",
    "display(progress)\n",
    "\n",
    "for i in main_links:\n",
    "    try:\n",
    "        response = requests.get(i, verify=False)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        for link in soup.find_all('___','________________________________________________'):\n",
    "            category_links.append(url+link.get('href'))\n",
    "        \n",
    "        links = links + 1    \n",
    "        perc = round((links / leng) * 100, 2)\n",
    "        end_time = time.time()\n",
    "        predict = round((((end_time - start_time)/links)*(leng-links))/60,2)\n",
    "        print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN     '.format(links,leng,perc,predict), end='\\r')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print ('SOMETHING IS WRONG WITH {}'.format(link.get('href')))\n",
    "        pass\n",
    "\n",
    "    output = wi.Output()\n",
    "    progress.value = links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавляем номера страниц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "numbers = []\n",
    "leng = len(category_links)\n",
    "links = 0\n",
    "progress = IntProgress(min = 0, max = len(category_links), value = links, style={'bar_color': '#f08080'}, layout=Layout(width='20%', height='20px'))\n",
    "display(progress)\n",
    "\n",
    "for category in category_links:\n",
    "    try:\n",
    "        response = requests.get(category, verify=False)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        f = 1\n",
    "        n = soup.find('_____','_______________').text                     # достаем кол-во товаров в подкатегории\n",
    "        n = n.replace('(',\"\").replace(')', \"\")\n",
    "        k = math.ceil(int(n)/40)\n",
    "\n",
    "        while f <= k:\n",
    "            numbers.append(category+'?page={}'.format(f))\n",
    "            f = f + 1\n",
    "\n",
    "        links = links + 1\n",
    "        perc = round((links / leng) * 100, 2)\n",
    "        end_time = time.time()\n",
    "        predict = round((((end_time - start_time)/links)*(leng-links))/60,2)\n",
    "        print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN     '.format(links,leng,perc,predict), end='\\r')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print ('SOMETHING IS WRONG WITH {}      '.format(category), end='\\r')\n",
    "        pass\n",
    "    \n",
    "    output = wi.Output()\n",
    "    progress.value = links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем страницы продуктов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "full_path_art = []\n",
    "leng = len(numbers)\n",
    "links = 0\n",
    "progress = IntProgress(min = 0, max = len(numbers), value = links, style={'bar_color': '#f08080'}, layout=Layout(width='20%', height='20px'))\n",
    "display(progress)\n",
    "\n",
    "for url_num in numbers:\n",
    "    try:\n",
    "        response = requests.get(url_num, verify=False)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        for link in soup.find_all('a','productCardPictureLink active css-of3y3a'):\n",
    "            full_path_art.append(url_num+link.get('href'))\n",
    "        \n",
    "        links = links + 1\n",
    "        perc = round((links / leng) * 100, 2)\n",
    "        end_time = time.time()\n",
    "        predict = round((((end_time - start_time)/links)*(leng-links))/60,2)\n",
    "        print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN     '.format(links,leng,perc,predict), end='\\r')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print (' SOMETHING IS WRONG WITH {}       '.format(link.get('href')), end='\\r')\n",
    "        pass\n",
    "    \n",
    "    output = wi.Output()\n",
    "    progress.value = links\n",
    "\n",
    "df_full_path = pd.DataFrame(full_path_art)\n",
    "df_full_path.to_csv (\"full_path.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем полную информацию о ссылках на продукты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_full_path = pd.DataFrame(full_path_art)\n",
    "df_full_path.to_csv (\"full_path.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prod=pd.read_csv('full_path.csv',names=['1','2','3','4','category','subcategory','5','product','name','6'],\n",
    "encoding='cp1251',sep='/', skiprows=1)\n",
    "path_prod = path_prod.drop(columns=['1','2','3','4','5','6'])\n",
    "path_prod['path'] = 'https://www.auchan.ru/product/' + path_prod['name'] +'/'\n",
    "path_prod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразуем данные для разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prod=pd.read_csv('full_path.csv',names=['1','2','3','4','category','subcategory','5','product','name','6'],\n",
    "encoding='cp1251',sep='/', skiprows=1)\n",
    "path_prod = path_prod.drop(columns=['1','2','3','4','5','6'])\n",
    "path_prod['path'] = 'https://www.auchan.ru/product/' + path_prod['name'] +'/'\n",
    "\n",
    "cat = path_prod.category.unique()\n",
    "files_name = []\n",
    "\n",
    "for cat_name in cat:\n",
    "    df = path_prod.loc[(path_prod['category'] == cat_name)]\n",
    "    df = df.drop(columns=['category','subcategory','product','name'])\n",
    "    file_name = \"{}_part\".format(cat_name)\n",
    "    df.to_csv ('{}.csv'.format(file_name), index= False, header= False, sep=';')\n",
    "    files_name.append(file_name)\n",
    "\n",
    "prodycts_links = []\n",
    "for i in files_name:\n",
    "    prodycts_links.append(i+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор категории для загрузки товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(prodycts_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = 'aziya_part.csv'        # выбрать категорию из списка выше\n",
    "prod_cat=pd.read_csv(file, names=['links'])\n",
    "prod_cat = prod_cat['links'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем имя товара и артикул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "name_art = []\n",
    "links = 0\n",
    "leng = len(prod_cat)\n",
    "progress = IntProgress(min = 0, max = leng, value = links, style={'bar_color': '#f08080'}, layout=Layout(width='20%', height='20px'))\n",
    "display(progress)      \n",
    "\n",
    "for file in prod_cat:\n",
    "    try:\n",
    "        response = requests.get(file, verify=False)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "        name_art.append(file + soup.find('__','___________').text + '/'+ soup.find('td','css-1v23ygr').text)\n",
    "\n",
    "        links = links + 1\n",
    "        perc = round((links / leng) * 100, 2)\n",
    "        end_time = time.time()\n",
    "        predict = round((((end_time - start_time)/links)*(leng-links))/60,2)\n",
    "        print (' PROCESS: {}/{}  ||  {} %  ||  WAITING TIME {} MIN    '.format(links,leng,perc,predict), end='\\r')\n",
    "\n",
    "    except Exception as e:\n",
    "        print (' SOMETHING IS WRONG WITH {}           '.format(url), end='\\r')\n",
    "        pass\n",
    "\n",
    "    output = wi.Output()\n",
    "    progress.value = links\n",
    "\n",
    "#print(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(name_art)\n",
    "df.to_csv (\"df_final.csv\", index=False)       # УКАЗАТЬ ИМЯ ДЛЯ ИТОГОВОГО ФАЙЛА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('df_final.csv')\n",
    "df = df['0'].str.split('/', expand=True)\n",
    "df.columns=['0','1','2','3','Имя_ENG','Наименование','Артикул','7']\n",
    "df = df.drop(columns=['0','1','2','3','7'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение полученных данных с данными из Dbeaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prod = \"\"\"\n",
    "select sku, lvl_1, lvl_2, lvl_3, lvl_4 from products\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products  =  pd.read_sql(query_prod, greenplum)\n",
    "products['sku'] = products['sku'].astype(str)\n",
    "products.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(products, df, left_on='sku', right_on='Артикул')\n",
    "df_merged = df_merged[['Артикул', 'Наименование', 'lvl_1', 'lvl_2', 'lvl_3','lvl_4']]\n",
    "df_merged = df_merged.drop_duplicates ()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запись артикулов и продуктов и загрузка в SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_art = pd.DataFrame(name_art)\n",
    "df_art.to_csv (\"prd_art.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для загрузки в базу\n",
    "conn = create_engine('________________________________________________')\n",
    "\n",
    "table_path = 'table_table'          #УКАЗАТЬ НАИМЕНОВАНИЕ ТАБЛИЦЫ В SAS\n",
    "df_merged.to_sql(name=table_path, con=conn, schema='public', if_exists='replace')\n",
    "print('Залито в базу, путь: {}'.format(table_path))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
